version: '3.5'

# source: https://github.com/botleg/swarm-logging/blob/master/docker-stack.yml
# source: https://github.com/bvis/docker-prometheus-swarm/blob/master/docker-compose.logging.yml

# networks:
#   monitor_monitoring:
#     external:
#       name: monitor_monitoring

# NOTE: scope
# source: https://docs.docker.com/engine/extend/plugins_volume/#volumedrivercapabilities
# Supported scopes are global and local.
# Any other value in Scope will be ignored,
# and local is used.
# Scope allows cluster managers to handle the volume in different ways.
# For instance, a scope of global,
# signals to the cluster manager that it only needs to
# create the volume once instead of on each Docker host.
# # More capabilities may be added in the future.
# volumes:
#   esdata:
#     driver: local

# NOTE: Working version 10/12/2018
# docker run -it \
#     --rm \
#     -p 9200:9200 \
#     -p 9300:9300 \
#     --memory="600M" \
#     --cpus="1.5" \
#     --mount type=bind,src=$(pwd)/config/elasticsearch.yml,dst=/usr/share/elasticsearch/config/elasticsearch.yml \
#     --mount type=bind,src=$(pwd)/config/elasticsearch.jvm.options,dst=/usr/share/elasticsearch/config/jvm.options \
#     --env http.host='0.0.0.0' \
#     --env discovery.zen.minimum_master_nodes='1' \
#     --env discovery.type='single-node' \
#     --env ES_JAVA_OPTS="${ES_JAVA_OPTS}" \
#     docker.io/bossjones/elasticsearch:5.6.1 bash

services:
  elasticsearch:
    image: docker.io/bossjones/elasticsearch:5.6.1
    ports:
      - '9200:9200'
      - '9300:9300'
    environment:
      http.host: '0.0.0.0'
      discovery.zen.minimum_master_nodes: '1'
      discovery.type: 'single-node'
      ES_JAVA_OPTS: ${ES_JAVA_OPTS}
    networks:
      - traefik_proxy
    depends_on:
      - traefik
    deploy:
      labels:
      - "traefik.enable=true"
      - "traefik.basic.port=9200"
      - "traefik.backend=elasticsearch"
      - "traefik.backend.loadbalancer.stickiness=true"
      - "traefik.frontend.rule=Host:elasticsearch.scarlettlab.home"
      - "traefik.backend.loadbalancer.swarm=true"
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 60s
      resources:
        limits:
          memory: 600M
      placement:
        constraints:
          - node.labels.memory == high
          # - node.hostname == node4
    configs:
      - source: es-config
        target: /usr/share/elasticsearch/config/elasticsearch.yml
      - source: es-jvm-options
        target: /usr/share/elasticsearch/config/jvm.options
    # volumes:
    #   - elasticsearch-data:/usr/share/elasticsearch/data:nocopy
    # SOURCE: volume decleration - https://blog.dahanne.net/2017/11/20/docker-swarm-and-nfs-volumes/
    volumes:
    - type: volume
      source: elasticsearch-data
      target: /usr/share/elasticsearch/data
      volume:
        nocopy: true
    logging:
      driver: json-file
      options:
        max-size: 25m
        max-file: 4

  # elasticsearch-cleaner:
  #   image: rycus86/elasticsearch-cleaner
  #   depends_on:
  #     - traefik
  #     - elasticsearch
  #     - fluentd
  #   networks:
  #     - traefik_proxy
  #   deploy:
  #     replicas: 1
  #     placement:
  #       constraints:
  #         - node.labels.memory == high
  #         # - node.hostname == node4
  #     resources:
  #       limits:
  #         memory: 16M
  #   environment:
  #     - BASE_URL=http://elasticsearch:9200
  #     - PATTERN=fluentd
  #     - MAX_INDICES=7
  #     - INTERVAL=10h
  #     - TIMEOUT=1m
  #   logging:
  #     driver: fluentd
  #     options:
  #       tag: app.elasticsearch.cleaner
  #       fluentd-address: 192.168.60.10:24224
  #       fluentd-async-connect: 'true'
  #       fluentd-sub-second-precision: 'true'

  # kibana:
  #   image: registry.scarlettlab.home/private/kibana:6.0.0
  #   deploy:
  #     replicas: 1
  #     resources:
  #       limits:
  #         memory: 128M
  #     # TODO /etc/auth-config should change when the routing stack gets updated
  #     labels:
  #       routing-auth-realm: Kibana Logs
  #       routing-auth: /etc/auth-config/kibana.auth.conf
  #       routing-host: logs.scarlettlab.home
  #       routing-port: 5601
  #   networks:
  #     - default
  #     - web
  #   ports:
  #     - 5601:5601
  #   logging:
  #     driver: json-file
  #     options:
  #       max-size: 25m
  #       max-file: 4

  # kibana:
  #   # image: docker.elastic.co/kibana/kibana:5.6.1
  #   image: docker.io/bossjones/kibana:5.6.1
  #   networks:
  #     - traefik_proxy
  #   deploy:
  #     replicas: 1
  #     resources:
  #       limits:
  #         memory: 128M
  #     # TODO /etc/auth-config should change when the routing stack gets updated
  #     labels:
  #       routing-auth-realm: Kibana Logs
  #       routing-auth: /etc/auth-config/kibana.auth.conf
  #       routing-host: logs.scarlettlab.home
  #       routing-port: 5601
  #   # networks:
  #   #   - default
  #   #   - web
  #   ports:
  #     - 5601:5601
  #   logging:
  #     driver: json-file
  #     options:
  #       max-size: 25m
  #       max-file: 4

  fluentd:
    image: docker.io/bossjones/fluentd:latest
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 96M
    configs:
      - source: fluent-config
        target: /fluentd/etc/fluent.conf
    ports:
      - 24224:24224
      - 24224:24224/udp
    environment:
      - RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR=0.8
    logging:
      driver: json-file
      options:
        max-size: 25m
        max-file: 4

configs:
  es-config:
    name: elasticsearch-config-${ELASTICSEARCH_YML}
    file: ./config/elasticsearch.yml
  es-jvm-options:
    name: elasticsearch-jvm-options-${ELASTICSEARCH_JVM_OPTIONS}
    file: ./config/elasticsearch.jvm.options
  fluent-config:
    name: fluent-config-${FLUENT_CONFIG}
    file: ./config/fluent.config

# volumes:
#   elasticsearch-data:
#     driver: local
#     driver_opts:
#       type: "nfs4"
#       device: ":/elasticsearch-data"
#       # o: addr=192.168.60.10,rsize=8192,wsize=8192,timeo=15,hard,intr
#       o: addr=192.168.60.10,rsize=8192,wsize=8192,timeo=15,hard,intr,nolock,soft,rw

# o: addr=192.168.60.10,rsize=8192,wsize=8192,timeo=15,hard,intr
volumes:
  elasticsearch-data:
    driver: local
    driver_opts:
      type: nfs
      device: ":/mnt/nfs/data/elasticsearch-data"
      o: addr=192.168.60.10,rsize=8192,wsize=8192,timeo=15,hard,intr,nolock,soft,rw

# Alternative
# docker volume create --driver local \
#   --opt type=nfs4 \
#   --opt o=addr=192.168.60.10,uid=1000,gid=1000,rsize=8192,wsize=8192,timeo=15,hard,intr,nolock,soft,rw \
#   --opt device=:/mnt/nfs/data/elasticsearch-data \
#   elasticsearch-data

# Alternative
# docker volume create --driver local \
#   --opt type=nfs \
#   --opt o=addr=192.168.60.10,rsize=8192,wsize=8192,timeo=15,hard,intr,nolock,soft,rw \
#   --opt device=:/mnt/nfs/data/elasticsearch-data \
#   elasticsearch-data

networks:
  web:
    external: true
    name: home-web
  docker:
    external: true
    name: home-docker
  traefik_proxy:
    external: true
    driver: overlay
    name: traefik_proxy
